{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 常用命令汇总\n",
    "[PyTorch Tutorial](https://pytorch.org/tutorials/)\n",
    "\n",
    "[PyTorch Python API](https://pytorch.org/docs/stable/torch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.tensor类矩阵数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 直接创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x = torch.rand(5, 3)\n",
    "x = torch.zeros(5, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "x = torch.tensor([5.5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 与其他模块的联动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x.item()\n",
    "b = x.numpy()\n",
    "c = np.ones(5)\n",
    "d = torch.from_numpy(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵数据的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵重构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4906, 1.6711, 2.0519],\n",
      "        [1.2254, 1.1406, 2.9968]])\n"
     ]
    }
   ],
   "source": [
    "print(x.view(2,3))  #按指定形状不替换重构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络解算流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络的搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单层网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = nn.Linear(5, 3, bias=True) #产生5输入、3输出的线性层，默认包含偏差（bias项可缺省）\n",
    "conv1 = nn.Conv2d(3, 6, 5) #产生3输入、6输出、5*5大小的convolution层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算图定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(6,4)\n",
    "x.unsqueeze_(0)  #为单个数据添加Batch层，以符合输入维度\n",
    "x = F.relu(x) #Relu层\n",
    "x = F.max_pool2d(x, (2, 2)) #最大值Pool层，2*2区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络nn.Module 容器\n",
    "  建立一个神经网络，以ReNet的建立为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"定义不同容器.\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"定义前向传播流程.\"\"\"\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()  #生成定义好的Net对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代价函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.functional' has no attribute 'CrossEntropyLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-af19126ed13a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#定义MSE均方损失容器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcriterion_crossentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'CrossEntropyLoss'"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()  #定义MSE均方损失容器\n",
    "criterion_crossentropy = F.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运算器定义\n",
    "引用搭建好模型中的参数构建运算器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)  #定义SGD运算器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()  #所有参数梯度归零\n",
    "optimizer.zero_grad()  #定义了运算器之后，直接将运算器的参数缓存归零"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "\n",
    "out = net(input) #完成一次完整前向传播\n",
    "loss = criterion(out, target)  # 计算代价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 后向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000026A02590C88>\n",
      "<AddmmBackward object at 0x0000026A02590CC8>\n",
      "<AccumulateGrad object at 0x0000026A02590C88>\n"
     ]
    }
   ],
   "source": [
    "grad_randn = torch.randn(1, 10)\n",
    "loss.backward() #完成一次完整前向传播\n",
    "# out.backward(grad_randn)  #从特定层开始后向传播，注意每个参数一次前传后只能后传一次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-9.7367e-02, -2.7092e-02,  9.1190e-03],\n",
      "         [ 7.6643e-02,  1.2557e-01,  6.9187e-02],\n",
      "         [-6.0590e-02,  7.4422e-02, -1.3327e-01]],\n",
      "\n",
      "        [[ 1.0864e-01,  1.1039e-01,  9.6965e-02],\n",
      "         [-3.0777e-02, -2.8466e-02,  9.5951e-02],\n",
      "         [ 2.6086e-02, -1.0719e-01, -7.2378e-02]],\n",
      "\n",
      "        [[ 5.0360e-02, -3.4538e-02,  1.0904e-01],\n",
      "         [ 1.0685e-01, -1.3312e-01,  2.5779e-02],\n",
      "         [-3.6451e-03, -9.2713e-02, -1.0369e-01]],\n",
      "\n",
      "        [[ 2.6505e-02, -6.0805e-02, -8.4293e-03],\n",
      "         [-9.1020e-02,  2.7264e-02,  5.1203e-02],\n",
      "         [ 8.6776e-02,  1.0141e-01, -1.2973e-01]],\n",
      "\n",
      "        [[-1.2748e-01,  8.1006e-02,  1.0380e-02],\n",
      "         [-1.2379e-01,  9.0663e-02,  3.2367e-02],\n",
      "         [ 2.0242e-02,  6.1821e-02, -5.9500e-02]],\n",
      "\n",
      "        [[-5.6891e-03,  9.6778e-02,  6.2581e-02],\n",
      "         [ 1.2645e-01, -9.5265e-02,  1.0756e-01],\n",
      "         [ 7.4238e-05,  4.4013e-02,  8.6604e-02]]], grad_fn=<SelectBackward>)\n",
      "tensor([ 0.1099, -0.0925,  0.0611,  0.1524, -0.2210,  0.0813,  0.0038, -0.0014,\n",
      "         0.1175, -0.1102,  0.0141,  0.1927, -0.0042, -0.0554, -0.0815,  0.0746])\n"
     ]
    }
   ],
   "source": [
    "params=list(net.parameters())  #获取全部参数列表\n",
    "print(net.conv2.weight[15])  # 获取指定层指定参数，例：conv1层第16神经元参数\n",
    "print(net.conv2.bias.grad)  # 获取指定层指定梯度，例：conv1层偏差项梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 升级参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()  #单步优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
